{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Varying Node Capacities\n",
    "\n",
    "Evaluation of solution quality for abilene network with increasing node capacities.\n",
    "\n",
    "## Scenario\n",
    "\n",
    "* Network: Abilene: 11 nodes, 14 edges\n",
    "* All nodes with random cap between (0-2)*(1,2,3,4,5,6,7)\n",
    "* 4 Ingress Nodes\n",
    "* MMPP flow arrival with inter-arr time 8-12\n",
    "* Flow weight = 1, Delay weight = 0\n",
    "\n",
    "## Approaches\n",
    "\n",
    "* BSP: 30 repetition per scenario\n",
    "* Load Balance: 30 repetition per scenario\n",
    "* Shortest Path: 30 repetition per scenario\n",
    "* DRL: \n",
    "  * 100k training  with 10 different seeds on larger networks --> auto select best one\n",
    "  * 30x 1 testing episode with best agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from operator import itemgetter\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx\n",
    "%matplotlib inline\n",
    "\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "# prefix for saving plot files\n",
    "plot_prefix = 'var-node-cap_mmpp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusted version\n",
    "def read_results_over_networks(dir, df=None, rf=None, best_only=False, network_dir=None, skip_rf=True, alg_name=None):\n",
    "    \"\"\"Read result files in the directory and append results to the data frame\"\"\"\n",
    "    if df is None:\n",
    "        df = pd.DataFrame()\n",
    "    if rf is None:\n",
    "        rf = pd.DataFrame()\n",
    "\n",
    "    if network_dir is not None:\n",
    "        dir = f'{network_dir}/{dir}'\n",
    "    \n",
    "    for root, sub_dirs, files in os.walk(dir):\n",
    "        if len(files) > 0 and (not '.ipynb_checkpoints' in root):                \n",
    "            if 'best' in root or not best_only:\n",
    "                # read metrics at end of simulation (last row)\n",
    "                df_metrics = pd.read_csv(f'{root}/metrics.csv')\n",
    "                data = df_metrics.tail(1)\n",
    "                # get the last placement\n",
    "                df_placements = pd.read_csv(f'{root}/placements.csv').groupby('time')\n",
    "                placements = pd.concat(deque(map(itemgetter(1), df_placements), maxlen=1))\n",
    "                \n",
    "                \n",
    "                # add algorithm name, number of ingress nodes, and number of vnfs as columns\n",
    "                with open(f'{root}/input.yaml', 'r') as f:\n",
    "                    inputs = yaml.load(f, Loader=yaml.Loader)\n",
    "                if alg_name is None:\n",
    "                    alg_name = inputs['algorithm']\n",
    "                \n",
    "                # read number of nodes in network\n",
    "                network_file = [filename for filename in files if \".graphml\" in filename]\n",
    "                assert len(network_file) == 1\n",
    "                network_file = network_file[0]\n",
    "                if network_dir is None:\n",
    "                    network_dir = network_file.split('.')[0]\n",
    "                nx_network = networkx.read_graphml(f'{root}/{network_file}')\n",
    "                num_nodes = nx_network.number_of_nodes()\n",
    "                network_cap = sum([n[1].get('NodeCap') for n in nx_network.nodes(data=True)])\n",
    "                \n",
    "                data.insert(loc=0, column='network', value=network_dir)\n",
    "                data.insert(loc=1, column='network_cap', value=network_cap)\n",
    "                data.insert(loc=2, column='algorithm', value=alg_name)\n",
    "                data.insert(loc=3, column='num_nodes', value=num_nodes)\n",
    "                data.insert(loc=4, column='num_ingress', value=inputs['num_ingress'])\n",
    "                data.insert(loc=data.columns.size, column='num_vnfs', value=placements['sf'].size)\n",
    "                \n",
    "                df = df.append(data, ignore_index=True, sort=True)\n",
    "                fix_dtypes(df)\n",
    "                df.sort_values(['algorithm', 'num_nodes'], inplace=True)\n",
    "                df = df[['network', 'algorithm', 'num_nodes', 'num_ingress', 'network_cap', 'total_flows', 'successful_flows', 'dropped_flows', 'in_network_flows', 'avg_end2end_delay', 'num_vnfs']]\n",
    "\n",
    "                if not skip_rf:\n",
    "                    # Reading resource metrics and creating a new Resource Dataframe\n",
    "                    # Getting the last group using the Deque operation\n",
    "                    rf_resources = pd.read_csv(f'{root}/node_metrics.csv').groupby('time')\n",
    "                    resources = pd.concat(deque(map(itemgetter(1), rf_resources), maxlen=1))\n",
    "                    resources.insert(loc=0, column='network', value=network_dir)\n",
    "                    resources.insert(loc=1, column='network_cap', value=network_cap)\n",
    "                    resources.insert(loc=2, column='algorithm', value=inputs['algorithm'])\n",
    "                    resources.insert(loc=3, column='num_nodes', value=num_nodes)\n",
    "                    resources.insert(loc=4, column='num_ingress', value=inputs['num_ingress'])\n",
    "                    rf = rf.append(resources, ignore_index=True, sort=True)\n",
    "                    rf.sort_values(['algorithm', 'num_nodes'], inplace=True)\n",
    "                \n",
    "    #Add percentage of successful flows\n",
    "    succ_percentage = []\n",
    "    for index, row in df.iterrows():\n",
    "        succ_percentage.append(row['successful_flows'] / row['total_flows'] * 100)\n",
    "    df['successful_percentage'] = succ_percentage\n",
    "    return df, rf\n",
    "\n",
    "\n",
    "def fix_dtypes(df):\n",
    "    \"\"\"Set correct dtypes and order\"\"\"\n",
    "    df['avg_end2end_delay'] = pd.to_numeric(df['avg_end2end_delay'])\n",
    "    df['total_flows'] = pd.to_numeric(df['total_flows'])\n",
    "    df['successful_flows'] = pd.to_numeric(df['successful_flows'])\n",
    "    df['dropped_flows'] = pd.to_numeric(df['dropped_flows'])\n",
    "    df['in_network_flows'] = pd.to_numeric(df['in_network_flows'])\n",
    "    \n",
    "    \n",
    "def df_mean_std(df, group_by=['network', 'algorithm', 'num_nodes', 'num_ingress' , 'network_cap']):\n",
    "    \"\"\"Return 2 new dfs with 1) average and 2) std values\"\"\"\n",
    "    df_mean = df.groupby(group_by).mean().reset_index()\n",
    "    df_std = df.groupby(group_by).std().reset_index()\n",
    "    return df_mean, df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read results\n",
    "df = pd.DataFrame()\n",
    "rf = pd.DataFrame()\n",
    "\n",
    "df, rf = read_results_over_networks('drl', df, rf, best_only=True, alg_name='DRL')\n",
    "df, rf = read_results_over_networks('bsp', df, rf, best_only=False, alg_name='BSP')\n",
    "df, rf = read_results_over_networks('bsp-ad', df, rf, best_only=False, alg_name='BSP Ad.')\n",
    "df, rf = read_results_over_networks('sp', df, rf, best_only=False, alg_name='SP')\n",
    "df, rf = read_results_over_networks('lb', df, rf, best_only=False, alg_name='LB')\n",
    "\n",
    "df_mean, df_std = df_mean_std(df)\n",
    "# only select results with 4 ingress nodes\n",
    "df_mean = df_mean[df_mean['num_ingress'] == 4]\n",
    "df_std = df_std[df_std['num_ingress'] == 4]\n",
    "\n",
    "df_mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Successful Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.1, style='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_successful_flows(df_mean, df_std, filename=None):\n",
    "    algs=['DRL', 'BSP','BSP Ad.', 'SP', 'LB']\n",
    "    sns.set(font_scale=1, style='white')\n",
    "    markers = ['^', 'v', 's', 'D', '<', '>', 'P', 'X', 'o', '8', 'p']\n",
    "    fig, ax1 = plt.subplots(figsize=(4, 4))\n",
    "    sns.set(font_scale=1.1, style='white')\n",
    "\n",
    "    # plot successful flows\n",
    "    for i, algorithm in enumerate(algs):\n",
    "        alg_df_mean = df_mean[df_mean['algorithm'] == algorithm]\n",
    "        alg_df_std = df_std[df_std['algorithm'] == algorithm]\n",
    "        ax1.errorbar(alg_df_mean['network_cap'], alg_df_mean['successful_percentage'], yerr=alg_df_std['successful_percentage'], capsize=5,\n",
    "                    label='{}'.format(algorithm), marker=markers[i])\n",
    "\n",
    "    # set axis, title, legend\n",
    "    # ax1.set_title('Successful Flows')\n",
    "    ax1.set_xlabel('Total Node Capacity')\n",
    "    ax1.set_ylabel('Successful Flows [%]')\n",
    "    ax1.set_ylim(0, 105)\n",
    "\n",
    "    ax1.tick_params(axis='both', direction='inout', length=5, bottom=True, left=True, right=True, top=True)\n",
    "\n",
    "    # remove error bars from legend: https://stackoverflow.com/a/15551976/2745116\n",
    "    # get handles\n",
    "    handles, labels = ax1.get_legend_handles_labels()\n",
    "    # remove the errorbars\n",
    "    handles = [h[0] for h in handles]\n",
    "    # use them in the legend\n",
    "    ax1.legend(handles, labels, numpoints=1)\n",
    "\n",
    "    # ax1.legend()\n",
    "    if filename is not None:\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(f'plots/{filename}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plot_successful_flows(df_mean, df_std)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}